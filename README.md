# PathMNIST Explainable Deep Learning Model üöÄ

A **lightweight yet high-performing CNN model** designed for the **PathMNIST medical imaging dataset**.  
This model integrates **explainable AI (XAI)** techniques using **Integrated Gradients** for transparent decision-making, while also leveraging **SQLite for scalable attribution storage**.

With **over 91% test accuracy** and **97% training accuracy**, the model demonstrates **state-of-the-art efficiency, scalability, and explainability** in pathology image classification.

---

## üîç Introduction & Overview

Medical image classification is critical for **computer-aided diagnosis (CAD)**. However, black-box models often lack **interpretability**, limiting trust in clinical adoption.

This project introduces an **improved CNN architecture** with **explainability baked in**:

- Trained on the **PathMNIST dataset** (107,180 images).  
- Achieved **91.14% test accuracy** in just 25 epochs.  
- Uses **Captum‚Äôs Integrated Gradients** for interpretable attributions.  
- Stores explanations in a **scalable SQLite database** for downstream analysis.  

üëâ **Keywords:** AI Model, Deep Learning, CNN, Scalable AI, Lightweight Model, Medical Imaging, Explainable AI, Pathology, Integrated Gradients, SQLite  

---

## ‚ö° Key Features

- ‚úÖ **High Accuracy**: 97.11% training, 91.14% test accuracy.  
- ‚úÖ **Lightweight & Scalable**: Efficient CNN architecture deployable on edge and HPC systems.  
- ‚úÖ **Explainability Built-in**: Integrated Gradients for transparent predictions.  
- ‚úÖ **Data Augmentation**: Horizontal flips & rotations improve generalization.  
- ‚úÖ **Scalable Attribution Storage**: Explanations stored in **SQLite** for reproducibility.  
- ‚úÖ **Early Stopping + Scheduler**: Prevents overfitting, ensures stable training.  

---

## üìà Results & Benchmarks
![Ouput](./images/results.png)
- **Final Test Accuracy**: **91.14%**  
- **Peak Training Accuracy**: **97.11%**  
- Outperforms baseline CNNs for PathMNIST while maintaining **lightweight scalability**.  

| Metric             | Our Model |
| ------------------ | --------- |
| Training Accuracy  | 97.11%    |
| Test Accuracy      | 91.14%    |
| Epochs             | 25        |
| Explainability     | ‚úÖ IG Maps |
| DB Storage Support | ‚úÖ SQLite  |

---

## üèóÔ∏è Model Architecture

![Architecture Diagram](./images/architecture.png)

The architecture includes:

- Convolutional blocks with **BatchNorm + ReLU** for stability.  
- **Dropout layers** for regularization.  
- **Fully connected layers** for robust classification into 9 classes.  

---

## üìä Training Performance

Training ran for **25 epochs** with augmentation, Adam optimizer, and ReduceLROnPlateau scheduler.

![Training Accuracy and Loss](./images/accuracy_epoch.png)  

- Accuracy improved from **77.03% ‚Üí 97.11%** during training.  
- Loss decreased consistently, showing strong convergence.  

---

## ‚öôÔ∏è Installation & Usage

### 1Ô∏è‚É£ Clone Repository
```bash
git clone https://github.com/ShreyaVijaykumar/PathMNIST-XAI-Lightweight-Explainable-CNN-for-Medical-Imaging
cd pathmnist-explainable-cnn
```

### 2Ô∏è‚É£ Install Requirements
```bash
pip install -r requirements.txt
```

### 3Ô∏è‚É£ Run Training
```bash
python train.py
```

### 4Ô∏è‚É£ Run Evaluation + Explanations
```bash
python evaluate.py
```

---
## üîë Keywords
#AI #DeepLearning #ExplainableAI #XAI #CNN #MedicalAI #Pathology #MedicalImaging  
#PyTorch #PathMNIST #LightweightAI #ScalableAI #EdgeAI #OpenSourceAI #MLforHealth  
#IntegratedGradients #Captum #DatabaseAI #SQLite #HealthcareAI #ComputerVision  

